{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-vq7tdx0wkvV"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resize\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from skimage.transform import resize\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6aFWvZNmxgWa"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3697596502.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    image=np.load(Your Data)\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "image=np.load(Your Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YPOk9EStyXH2"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1193005334.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    labels=np.load(Your Labels)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "labels=np.load(Your Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "soxBDnQjnt7Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Model parameters\n",
    "num_classes = 7\n",
    "input_shape = (48,48,3)\n",
    "\n",
    "# Define the model architecture\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3,3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0009), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMguUZVYGFyC",
    "outputId": "1488de2c-eed5-4c10-e542-a3d329a6ff45"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(image[5])\n",
    "labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWpUIZeU1HFB"
   },
   "outputs": [],
   "source": [
    "x_val=np.load(Validation Data Set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86iZR4-L1OGx"
   },
   "outputs": [],
   "source": [
    "y_val=np.load(Validation Labesl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZ5f2Jcy1TZd",
    "outputId": "7f167d62-e0ed-4309-fa66-df472d24d4ac"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_val[15])\n",
    "y_val[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M30rqI5B6TsK",
    "outputId": "2d274e77-3dce-4022-e073-8be5ba92cf2a"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=25, verbose=1, restore_best_weights=True, min_delta=0.01, \n",
    "                              baseline=0.6)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejFOg-vOyxRG",
    "outputId": "aeab9df9-d410-42db-efcd-a5354724ad1f"
   },
   "outputs": [],
   "source": [
    "model.fit(image, labels, epochs=25, batch_size=300, validation_data=(x_val,y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-z7EZxuPJpBX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14Rz-yJXyz1N"
   },
   "outputs": [],
   "source": [
    "model.save('MyModelFaceRecogD3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Z1bPbZfGCxD"
   },
   "outputs": [],
   "source": [
    "model_=load_model('/kaggle/working/MyModelFaceRecogD5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyeLpAAWvTL3"
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('/content/PrivateTest_2034433.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3TBLTB5vDAC"
   },
   "outputs": [],
   "source": [
    "img=img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTMFK4jVvj9R"
   },
   "outputs": [],
   "source": [
    "img=img.reshape(1,48,48,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbiCpgl4vqui",
    "outputId": "e07954ab-4c20-410d-d9aa-4ae419ebe7e3"
   },
   "outputs": [],
   "source": [
    "np.argmax(model.predict(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [0,1,2,3,4,5,6] Stand for [Angry,Sad,Fear,Happy,Neutral,Disgust,Surprise]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **From Here You Can Run the live Camera**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZdMixfsvtFh"
   },
   "outputs": [],
   "source": [
    "\n",
    "new_model=load_model('MyModelFaceRecogD6.h5')\n",
    "test_img=cv2.imread('happy-boy.jpg')\n",
    "test_img.shape\n",
    "plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
    "faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    " \n",
    "gray=cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces=faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    roi_gray=gray[y:y+h, x:x+w]\n",
    "    roi_color=test_img[y:y+h, x:x+w]\n",
    "    cv2.rectangle(test_img, (x,y), (x+w,y+h), (255,0,0),2)\n",
    "    facess=faceCascade.detectMultiScale(roi_gray)\n",
    "    \n",
    "    if len(facess) == 0:\n",
    "        print(\"Face not detected\")\n",
    "    else:\n",
    "        for (ex,ey,ew,eh) in facess:\n",
    "            face_roi=roi_color[ey: ey+eh, ex: ex+ew]\n",
    "\n",
    "face_roi=cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(face_roi)\n",
    "finalimage=cv2.resize(face_roi , (48,48))\n",
    "finalimage1=np.expand_dims(finalimage, axis=0)\n",
    "finalimage=finalimage1/255.0\n",
    "\n",
    "\n",
    "prediction=new_model.predict(finalimage)\n",
    "prediction\n",
    "path=\"haarcascade_frontalface_default.xml\"\n",
    "font_scale=1.6\n",
    "font=cv2.FONT_ITALIC\n",
    "\n",
    "rectangle_bgr=(255,255,255)\n",
    "img=np.zeros((500,500))\n",
    "\n",
    "text=\"some text in a boxl\"\n",
    "\n",
    "(text_width, text_height)=cv2.getTextSize(text,font, fontScale=font_scale, thickness=1)[0]\n",
    "text_offset_x=10\n",
    "text_offset_y=img.shape[0]-25\n",
    "\n",
    "box_coords=((text_offset_x,text_offset_y),(text_offset_x+text_width+2,text_offset_y-text_height-2))\n",
    "\n",
    "cv2.rectangle(img, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)\n",
    "\n",
    "cv2.putText(img, text, (text_offset_x, text_offset_y), font, fontScale=font_scale, color=(0,0,115), thickness=1)\n",
    "\n",
    "cap=cv2.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    cap=cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot Open Camera\")\n",
    "\n",
    "while True:\n",
    "    ret,test_img=cap.read()\n",
    "\n",
    "    faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    gray=cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "    faces=faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "\n",
    "    for x,y,w,h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color=test_img[y:y+h, x:x+w]\n",
    "        cv2.rectangle(test_img, (x,y), (x+w,y+h), (255,0,0),2)\n",
    "        facess=faceCascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex,ey,ew,eh) in facess:\n",
    "                face_roi=roi_color[ey: ey+eh, ex: ex+ew]\n",
    "\n",
    "\n",
    "    face_roi=cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "    finalimage=cv2.resize(face_roi, (48,48))\n",
    "    finalimage=np.expand_dims(finalimage, axis=0)\n",
    "    finalimage=finalimage/255.0\n",
    "\n",
    "    finalimage=finalimage.reshape(1,48,48,3)\n",
    "\n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    prediction=new_model.predict(finalimage)\n",
    "\n",
    "    font_scale=1.5\n",
    "    font=cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "    if (np.argmax(prediction)==0):\n",
    "        status= \"Angry\"\n",
    "\n",
    "        x1,y1,w1,h1=0,0,175,75\n",
    "        cv2.rectangle(test_img, (x1,x1),(x1+w1, y1+h1),(0,0,0), -1)\n",
    "        cv2.putText(test_img, status, (x1+int(w1/10),y1+int(h1/2)), cv2.FONT_HERSHEY_PLAIN, 0.3, (0,0,255),2)\n",
    "        cv2.putText(test_img, status,(100,150), font , 3, (0,0,255),2, cv2.LINE_4)\n",
    "        cv2.rectangle(test_img, (x,y), (x+w, y+h), (112,0,25))\n",
    "\n",
    "\n",
    "    elif (np.argmax(prediction)==1):\n",
    "        status= \"Disgust\"\n",
    "\n",
    "        x1,y1,w1,h1=0,0,175,75\n",
    "        cv2.rectangle(test_img, (x1,x1),(x1+w1, y1+h1),(0,0,0), -1)\n",
    "        cv2.putText(test_img, status, (x1+int(w1/10),y1+int(h1/2)), cv2.FONT_HERSHEY_PLAIN, 0.3, (0,0,255),2)\n",
    "        cv2.putText(test_img, status,(100,150), font , 3, (0,0,255),2, cv2.LINE_4)\n",
    "        cv2.rectangle(test_img, (x,y), (x+w, y+h), (112,0, 25))\n",
    "    \n",
    "    elif (np.argmax(prediction)==2):\n",
    "        status= \"Fear\"\n",
    "\n",
    "        x1,y1,w1,h1=0,0,175,75\n",
    "        cv2.rectangle(test_img, (x1,x1),(x1+w1, y1+h1),(0,0,0), -1)\n",
    "        cv2.putText(test_img, status, (x1+int(w1/10),y1+int(h1/2)), cv2.FONT_HERSHEY_PLAIN, 0.3, (0,0,255),2)\n",
    "        cv2.putText(test_img, status,(100,150), font , 3, (0,0,255),2, cv2.LINE_4)\n",
    "        cv2.rectangle(test_img, (x,y), (x+w, y+h), (112,0, 25))\n",
    "\n",
    "    elif (np.argmax(prediction)==3):\n",
    "        status= \"Happy\"\n",
    "\n",
    "        x1,y1,w1,h1=0,0,175,75\n",
    "        cv2.rectangle(test_img, (x1,x1),(x1+w1, y1+h1),(0,0,0), -1)\n",
    "        cv2.putText(test_img, status, (x1+int(w1/10),y1+int(h1/2)), cv2.FONT_HERSHEY_PLAIN, 0.3, (0,0,255),2)\n",
    "        cv2.putText(test_img, status,(100,150), font , 3, (0,0,255),2, cv2.LINE_4)\n",
    "        cv2.rectangle(test_img, (x,y), (x+w, y+h), (112,0, 25))\n",
    "\n",
    "    elif (np.argmax(prediction)==4):\n",
    "        status= \"Sad\"\n",
    "\n",
    "        x1,y1,w1,h1=0,0,175,75\n",
    "        cv2.rectangle(test_img, (x1,x1),(x1+w1, y1+h1),(0,0,0), -1)\n",
    "        cv2.putText(test_img, status, (x1+int(w1/10),y1+int(h1/2)), cv2.FONT_HERSHEY_PLAIN, 0.3, (0,0,255),2)\n",
    "        cv2.putText(test_img, status,(100,150), font , 3, (0,0,255),2, cv2.LINE_4)\n",
    "        cv2.rectangle(test_img, (x,y), (x+w, y+h), (112,0, 25))\n",
    "    \n",
    "    elif (np.argmax(prediction)==5):\n",
    "        status= \"Surprise\"\n",
    "\n",
    "        x1,y1,w1,h1=0,0,175,75\n",
    "        cv2.rectangle(test_img, (x1,x1),(x1+w1, y1+h1),(0,0,0), -1)\n",
    "        cv2.putText(test_img, status, (x1+int(w1/10),y1+int(h1/2)), cv2.FONT_HERSHEY_PLAIN, 0.3, (0,0,255),2)\n",
    "        cv2.putText(test_img, status,(100,150), font , 3, (0,0,255),2, cv2.LINE_4)\n",
    "        cv2.rectangle(test_img, (x,y), (x+w, y+h), (112,0, 25))\n",
    "\n",
    "    else:\n",
    "        status= \"Neutral\"\n",
    "\n",
    "        x1,y1,w1,h1=0,0,175,75\n",
    "        cv2.rectangle(test_img, (x1,x1),(x1+w1, y1+h1),(0,0,0), -1)\n",
    "        cv2.putText(test_img, status, (x1+int(w1/10),y1+int(h1/2)), cv2.FONT_HERSHEY_PLAIN, 0.3, (0,255,0),2)\n",
    "        cv2.putText(test_img, status,(100,150), font , 3, (0,0,255),2, cv2.LINE_4)\n",
    "        cv2.rectangle(test_img, (x,y), (x+w, y+h), (112,0,25))\n",
    "\n",
    "\n",
    "    cv2.imshow('Face Emotion Recognition', test_img)\n",
    "\n",
    "    if cv2.waitKey(2) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
